{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"41_Performance_일반화성능.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cVB9pY-v8uv5"},"source":["# 일반화 성능 : 한번 예측한 결과는 믿을만 한가?\n","---------------\n","\n"]},{"cell_type":"code","metadata":{"id":"GVvCef6A8uv6"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N8eruHyUkrBJ"},"source":["## 1.Data 가져와서 둘러보기"]},{"cell_type":"code","metadata":{"id":"7LRAB0OAlR3d"},"source":["# 데이터를 불러옵시다.\n","iris = pd.read_csv(\"https://raw.githubusercontent.com/DA4BAM/dataset/master/iris.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z1ahypi3irLz"},"source":["# 데이터를 살펴봅시다.\n","iris.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HGHlgWSwtSYh"},"source":["iris.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KkU_Yo1q4SDm"},"source":["## 2.Random Sampling\n","\n","* 데이터를 랜덤에서 분할하여 모델링 & 예측을 수행합니다.\n","* iris는 feature들이 모두 숫자이므로 dummy variable은 필요하지 않음\n","* Scaling만 필요\n"]},{"cell_type":"markdown","metadata":{"id":"j21PsRN_VtIp"},"source":["### 2.1.반복 실행해 봅시다.\n"]},{"cell_type":"code","metadata":{"id":"loMtk47mwXmF"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.tree import DecisionTreeClassifier, plot_tree"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JZX93xazwZia"},"source":["* 아래 셀은 데이터 분할 > 스케일링 > 모델링 코드를 모두 모아놓았습니다.\n","* Ctrl+Enter로 반복 실행해 봅시다. "]},{"cell_type":"code","metadata":{"id":"joxeAbTW55OM"},"source":["# 데이터 분할\n","target = 'Species'\n","x = iris.drop(target, axis = 1)\n","y = iris.loc[:, target]\n","\n","train_x, val_x, train_y, val_y = train_test_split(x, y, test_size=0.3)\n","\n","# DecisionTree 모델링\n","model = DecisionTreeClassifier(max_depth = 3)\n","model.fit(train_x, train_y)\n","model_pred_val = model.predict(val_x)\n","accuracy_score(val_y, model_pred_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ntIV7Zb65Bo9"},"source":["정분류율은 몇 %인가요?  \n","값이 달라지나요? 값이 달라지는 원인은 무엇인가요?   \n","값이 달라진다면 모델의 성능을 어떻게 믿을 수 있을까요?  "]},{"cell_type":"code","metadata":{"id":"i27qYefNVtIt"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g5oXx34xVtIw"},"source":["### 2.2.여러번 반복해서 평균을 계산해 봅시다."]},{"cell_type":"code","metadata":{"id":"aNh52PbFVtIw"},"source":["# 20번 반복 실행하여 결과를 담아 냅시다.\n","\n","result = []\n","for i in range(1,21):\n","    train_x, val_x, train_y, val_y = train_test_split(x, y, test_size=0.3)\n","\n","    model = DecisionTreeClassifier(max_depth = 3)\n","    model.fit(train_x, train_y)\n","    model_pred_val = model.predict(val_x)\n","    result.append(accuracy_score(val_y, model_pred_val))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O3uR6_DaVtIy"},"source":["평균과 표준편차를 구해 봅시다."]},{"cell_type":"code","metadata":{"id":"V8VeYQ3AVtIy"},"source":["np.mean(result), np.std(result)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xXB0tR4zDk1W"},"source":["np.mean(result) - 2* np.std(result), np.mean(result) + 2* np.std(result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lkHBHw03VtI0"},"source":["값의 분포를 살짝 살펴보면"]},{"cell_type":"code","metadata":{"id":"cz6-yOEhVtI1"},"source":["# matplotlib histogram\n","plt.boxplot(result)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lNRwL8xqngMk"},"source":["#### (옵션) max_depth 값을 달리하며 20회씩 수행하고 결과를 비교해 봅시다."]},{"cell_type":"code","metadata":{"id":"f9uP7w5WxkqS"},"source":["# 20번 반복 실행하여 결과를 담아 냅시다.\n","acc = []\n","m_depth = []\n","for d in [1,2,3,4] :\n","    for i in range(1,21):\n","        train_x, val_x, train_y, val_y = train_test_split(x, y, test_size=0.3)\n","\n","        model = DecisionTreeClassifier(max_depth = d)\n","        model.fit(train_x, train_y)\n","        model_pred_val = model.predict(val_x)\n","        acc.append(accuracy_score(val_y, model_pred_val))\n","        m_depth.append(d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kLXj-6X1n-pL"},"source":["result1 = pd.DataFrame({'maxDepth': m_depth, 'Acc':acc})\n","result1.boxplot('Acc', 'maxDepth')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UBPTMq5HrdkA"},"source":["### 실습 : knn 알고리즘으로 실습해 봅시다.\n","\n","1. k를 지정하지 말고(default)로 50회 수행한 후 결과를 담고 평균으로 일반화 성능을 얻어 봅시다.\n","2. k를 3,5,7,9 로 조정하며, 각 50회씩 수행한 후 결과를 담고, 각 분포로 성능을 비교해 봅시다.\n"]},{"cell_type":"code","metadata":{"id":"Lr3rMhq-rh_V"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"12Qc3EDKr7g7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sPUp6dQ4r7bb"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vR5GrTaEr7Up"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O4AFcGL6rzQt"},"source":["## 3.k-fold Cross Validation\n","\n","계획적으로 분할, 학습, 검증하는 방식을 사용해 봅시다!\n"]},{"cell_type":"code","metadata":{"id":"JOQLMbIVX-Bq"},"source":["# 다시 데이터 가져와서\n","iris = pd.read_csv(\"https://raw.githubusercontent.com/DA4BAM/dataset/master/iris.csv\")\n","\n","# features와 target 분리\n","target = 'Species'\n","x = iris.drop(target, axis = 1)\n","y = iris.loc[:, target]\n","\n","# train+val : test = 8 : 2\n","train_val_x, test_x, train_val_y, test_y = train_test_split(x, y, test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MuJJNyk9VtJx"},"source":["* cross validation 함수를 이용하여 모델을 검증합니다."]},{"cell_type":"code","metadata":{"id":"ayrREkKg6zUv"},"source":["# 필요햔 패키지, 함수 로딩\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","# 모델 선언 \n","model = DecisionTreeClassifier(max_depth = 3)\n","\n","# train + validation set을 이용하여 학습, 예측, 평가를 한번에. (여기서는 .fit 이 아님!)\n","cv_result = cross_val_score(model, train_val_x, train_val_y, cv=10)\n","print(cv_result)\n","print(cv_result.mean())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YdIie1qHo5eN"},"source":["# 역시 max_depth 값을 조정해 가며 성능을 비교해 봅시다.\n","# 100번 반복 실행하여 결과를 담아 냅시다.\n","scores = []\n","m_depth = []\n","for d in [1,2,3,4] :\n","    model = DecisionTreeClassifier(max_depth = d)\n","    cv_result = cross_val_score(model, train_val_x, train_val_y, cv=10)\n","    scores = scores + cv_result.tolist()\n","    m_depth = m_depth + [d]*10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gI7Zi7Eypoc2"},"source":["result2 = pd.DataFrame({'maxDepth': m_depth, 'Acc':scores})\n","result2.boxplot('Acc', 'maxDepth')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n0ugqBZTqx0j"},"source":["* 반복실행한 결과와 cv의 결과를 평균으로 비교해 봅시다.\n","* (주의) 데이터 사이즈(건수)가 많을 수록 둘의 편차는 줄어들 수 있습니다."]},{"cell_type":"code","metadata":{"id":"AbuEvUfEqNWs"},"source":["# result1\n","result1.groupby('maxDepth', as_index=False)['Acc'].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tw5PA56Vqra3"},"source":["result2.groupby('maxDepth', as_index=False)['Acc'].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jsmJjfrz3pdb"},"source":["우리는 여기서 나온 평균 성능을, 모델의 일반화 성능으로 이야기 할 수 있습니다~!"]},{"cell_type":"markdown","metadata":{"id":"8z8pzgX9gcmN"},"source":["## 실습 : knn알고리즘을 이용하여 k-fold cv 수행\n","1. fold의 갯수 5, \n","2. 이웃의 갯수(k 값) : 3,5,7,9 에 대해서\n","3. cv score 평균을 가지고 비교해 봅시다. "]},{"cell_type":"code","metadata":{"id":"2Z1lVZpMsPjj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nPTdCr9VsPhJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZrOaxcNsPd-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6m_QWg61oz46"},"source":["## 4.(Optional)학습 데이터 양에 따른 성능(Learning Curve)\n","\n","학습할 데이터를 증가시켜가면서 성능을 확인해보고자 합니다."]},{"cell_type":"code","metadata":{"id":"wVV0c1HWpP9k"},"source":["from sklearn.model_selection import learning_curve"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sS18c0eOuh1I"},"source":["from sklearn.tree import DecisionTreeClassifier\n","model = DecisionTreeClassifier(max_depth=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9tzzWf_pyRF"},"source":["x.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DA19DnxgpP6v"},"source":["tr_size, tr_scores, val_scores = learning_curve(model, x, y\n","                                                , train_sizes = range(1, 120)\n","                                                , cv = 5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PBAuV7c1rXMH"},"source":["# cv한 결과를 평균으로 집계 합시다.\n","tr_scores_mean = tr_scores.mean(axis = 1)\n","val_scores_mean = val_scores.mean(axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9XLFW2mtqPd_"},"source":["# 이제 그림을 그려봅시다.\n","plt.plot(tr_size, val_scores_mean)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LOjUGLsPqP8f"},"source":["# 어느 정도 데이터이면 학습하는데 충분할까요?\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TghoFD1Dup8h"},"source":["### 실습"]},{"cell_type":"code","metadata":{"id":"Qoduo9Z7Yy7X"},"source":["from sklearn.impute import SimpleImputer,KNNImputer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_R5IEO0QurGr"},"source":["# mobile data로 적정 학습 데이터 크기를 찾아 봅시다.\n","data_path = \"https://raw.githubusercontent.com/DA4BAM/dataset/master/mobile_NA2.csv\"\n","mobile = pd.read_csv(data_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V2AShivJvNcA"},"source":["# 데이터 전처리\n","target = 'CHURN'\n","x = mobile.drop(target, axis=1)\n","y = mobile.loc[:, target]\n","\n","# 변수 삭제\n","col_drop = ['id', 'COLLEGE']\n","x.drop(col_drop, axis = 1, inplace=True)\n","\n","# REPORTED_SATISFACTION 채우기\n","s_imputer = SimpleImputer(strategy = 'constant', fill_value = 'avg')\n","x[['REPORTED_SATISFACTION']] = s_imputer.fit_transform(x[['REPORTED_SATISFACTION']])\n","\n","# 가변수화\n","col_cat = ['REPORTED_SATISFACTION','REPORTED_USAGE_LEVEL','CONSIDERING_CHANGE_OF_PLAN']\n","for v in col_cat : \n","    dumm = pd.get_dummies(x[v], prefix= v)\n","    x = pd.concat([x, dumm], axis=1)\n","    x.drop(v, axis=1, inplace=True)\n","\n","col_x = list(x)\n","house_knnimp = KNNImputer()\n","x = house_knnimp.fit_transform(x)\n","x = pd.DataFrame(x, columns=col_x)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ytYWt8eKwQYq"},"source":["여기서 부터 시작입니다.\n"]},{"cell_type":"code","metadata":{"id":"tcN37M2nGWp3"},"source":["# 간단한 Decision Tree 모델을 선언합니다.\n","# max_depth는 3~5 사이로 결정\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bgMZKPYW9E61"},"source":["# learning curve를 수행합니다.\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tbuaelQd9hNx"},"source":["# plotting 하여 적절한 데이터 사이즈를 찾아 봅시다.\n","\n"],"execution_count":null,"outputs":[]}]}