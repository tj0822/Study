{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"51_Ensemble Basics I _ Bagging(iris,mobile).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AVG5bLhFJe6a"},"source":["# 51.Ensemble Basics I : Bagging\n","\n","---------------------------\n","실습데이터 : iris, mobile"]},{"cell_type":"code","metadata":{"id":"CoZmXqeWlTFL"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RODvVSk6x7pv"},"source":["# [1]랜덤 포레스트\n","\n","1. 나무를 몇 개 만들까? : n_estimators\n","2. 데이터들 부트스트래핑 할지 말지 : bootstrap = True\n","3. Feature는 얼마나 사용해야할까? : max_features = 'auto'"]},{"cell_type":"markdown","metadata":{"id":"kz_ucau3EEk6"},"source":["## 일단 실행해보기\n","쉬운 데이터로 실행해 봅시다."]},{"cell_type":"code","metadata":{"id":"Vq_RKzmvEMA1"},"source":["# 데이터 불러오기\n","\n","iris = pd.read_csv(\"https://raw.githubusercontent.com/DA4BAM/dataset/master/iris.csv\")\n","\n","from sklearn.model_selection import train_test_split\n","\n","# features와 target 분리\n","target = 'Species'\n","x = iris.drop(target, axis = 1)\n","y = iris.loc[:, target]  # target 변수.\n","\n","# 먼저 전체에서 train : test = 8 : 2\n","train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eDC3VMpbx7t5"},"source":["# 함수 불러오기\n","from sklearn.ensemble import RandomForestClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RQO5n49Q8uOn"},"source":["# 모델 선언하기\n","rfc = RandomForestClassifier(n_estimators = 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aYgTNk2317KD"},"source":["# 학습\n","rfc.fit(train_x, train_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"McBI3A7lHOWE"},"source":["# 예측\n","test_pred = rfc.predict(test_x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1IOh-Rkd2bm5"},"source":["# 평가 \n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mT1hlAs7Cy1q"},"source":["print(confusion_matrix(test_y, test_pred))\n","print(classification_report(test_y, test_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Kx80jnsFmlT"},"source":["# [2]Mobile 데이터로 Random Forest 모델링\n"]},{"cell_type":"markdown","metadata":{"id":"p7yEsDjAai1Y"},"source":["### 00.환경 준비와 데이터 로딩"]},{"cell_type":"markdown","metadata":{"id":"DFijIAllYnVQ"},"source":["#### 01.라이브러리 불러오기"]},{"cell_type":"code","metadata":{"id":"0wzhP3IXYnVQ"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m_HqzyEGa0tO"},"source":["#### 02.데이터 업로드 "]},{"cell_type":"code","metadata":{"id":"_1qxGFx4gCjl"},"source":["# mobile data\n","path = \"https://raw.githubusercontent.com/DA4BAM/dataset/master/mobile_cust_churn.csv\"\n","mobile = pd.read_csv(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YI3d8Z-KgCjo"},"source":["# train set과 holdout(test set) 두 df로 나눕니다.\n","target = 'CHURN'\n","x = mobile.drop(target, axis=1)\n","y = mobile.loc[:, target]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LqKDm57CgIzn"},"source":["### 20.데이터 준비"]},{"cell_type":"markdown","metadata":{"id":"hLwr6FA2etvR"},"source":["#### 21.변수 정리"]},{"cell_type":"code","metadata":{"id":"5kTeuItgetvS"},"source":["x.drop('id', axis = 1, inplace = True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rilhRNR7etvS"},"source":["#### 22.NA 처리"]},{"cell_type":"markdown","metadata":{"id":"d6iaNuWAetvT"},"source":["#### 23.Feature Engineering"]},{"cell_type":"markdown","metadata":{"id":"VPSDOlVEetvT"},"source":["#### 24.Dummy Variable"]},{"cell_type":"code","metadata":{"id":"qWxtNr8detvT"},"source":["col_cat = ['REPORTED_SATISFACTION', 'REPORTED_USAGE_LEVEL', 'CONSIDERING_CHANGE_OF_PLAN' ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nh-cvD9YetvT"},"source":["# 범주형(명목형) 변수를 가변수로 만들고 붙여봅시다.\n","\n","for v in col_cat :\n","    dummies = pd.get_dummies(x[v], prefix=v)\n","    x = pd.concat([x, dummies], axis=1)\n","    x.drop(v, axis = 1, inplace=True)\n","\n","x.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KpTszhDeetvU"},"source":["#### 25.Scaling\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wX2gIfgmetvU"},"source":["#### 26.Data Split"]},{"cell_type":"code","metadata":{"id":"D79pAwz8etvU"},"source":["train_x, val_x, train_y, val_y = train_test_split(x, y, test_size=0.4, random_state=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TFFtVGN6etvU"},"source":["print(train_x.shape)\n","print(val_x.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XKCwnOC5i8PV"},"source":["## 실습1 : random forest 모델링\n","    * n_estimators = 10 으로 설정하고 모델링\n","    * test셋으로 예측하고 평가해 봅시다.\n"]},{"cell_type":"code","metadata":{"id":"HM2Oh8SeI3nN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6zUHgomWEsF7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aFIZR3G2lHNx"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lrMz1G6AlHb3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FMsEXaw3jKWc"},"source":["## 실습2 : random forest 모델링2\n","n_estimators = 10 는 적절한 것일까요? \n","\n","* grid search를 수행합니다.\n","    * tree의 갯수를 10~300까지 10개씩 증가\n","    * 모델링 후 cv 평가 결과를 차트로 그려봅시다. \n"]},{"cell_type":"code","metadata":{"id":"WANQgx49I3yo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lnkhWLYfJEul"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KMvfeRc1BuUE"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_m4QC-zQBuds"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZK-Tzoq9Bul_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pMyn3CrMI4To"},"source":["## (Optional) Random Forest에 대해서 조금 더 살펴봅시다.\n"]},{"cell_type":"markdown","metadata":{"id":"ITRHA-r9JTTr"},"source":["### OOB(out of bag) Error\n","random forest는 random sampling을 할때, 두가지 관점에서 random 입니다.  \n","1) 행에 대한 random sampling : train set을 2/3와 1/3로 나누고 2/3를 진짜학습하고 1/3로 평가합니다.이때 평가 오차가 oob error 입니다.\n","\n","2) 열에 대한 random : 트리의 노드마다 분할 기준으로 정할 변수를 random하게 추출합니다."]},{"cell_type":"code","metadata":{"id":"FHAC9zN5JDMB"},"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","#  oob_score = True 라고 설정\n","rfc = RandomForestClassifier(n_estimators = 10, oob_score = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NcjoqN78JDVL"},"source":["# 학습을 시킨다!\n","rfc.fit(train_x, train_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cDzZaQfsJPay"},"source":["# 학습을 시킨 후에 .oob_score_ 값을 확인해 볼 수 있습니다.\n","rfc.oob_score_"],"execution_count":null,"outputs":[]}]}